{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a7675f-f34f-4985-b337-71a7e3f18d6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Obesity Levels Dataset insights and obesity prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3425d-5a33-40f7-8372-5ad07bef33c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "PROGRESS_BAR_LENGTH = 100\n",
    "\n",
    "DATASET_FILENAME = Path(\"data\") / \"ObesityDataSet_raw_and_data_sinthetic.csv\"\n",
    "TRAIN_DATASET_FILENAME = Path(\"data\") / \"preprocessed\" / \"obesity_train_dataset.csv\"\n",
    "TEST_DATASET_FILENAME = Path(\"data\") / \"preprocessed\" / \"obesity_test_dataset.csv\"\n",
    "\n",
    "CATEGORICAL_COLUMNS = [\"Gender\", \"family_history_with_overweight\", \"FAVC\", \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\", \"Age_Category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396b0b5",
   "metadata": {},
   "source": [
    "# Data analysis and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0213b8-6565-46f5-b71b-7cff9d896aa9",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d36f9a-c6fd-4d92-81c9-8d00b5c3c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "full_dataset = pd.read_csv(DATASET_FILENAME) #TODO: If it does not exist, display error asking user to download dataset and link to DL\n",
    "print(f\"Dataset shape: {full_dataset.shape}\")\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ad07a",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "full_dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5319efb",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset[\"BMI\"] = full_dataset[\"Weight\"] / (full_dataset[\"Height\"])**2\n",
    "full_dataset[\"Age_Category\"] = pd.cut(full_dataset[\"Age\"], bins=[0, 18, 60, float(\"inf\")], labels=[\"Young\", \"Adult\", \"Elderly\"])\n",
    "full_dataset[\"Water_Intake_Per_Kg\"] = full_dataset[\"CH2O\"] / full_dataset[\"Weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc940a48",
   "metadata": {},
   "source": [
    "## Data insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83947274",
   "metadata": {},
   "source": [
    "### Full data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full dataset distribution\n",
    "plotsize = math.ceil(math.sqrt(full_dataset.shape[1]))\n",
    "plt.figure(layout=\"compressed\", figsize=(12, 12))\n",
    "\n",
    "for i, column in enumerate(full_dataset):\n",
    "    ax = plt.subplot(plotsize, plotsize, i + 1)\n",
    "    sns.histplot(full_dataset[column], kde=True, color=\"skyblue\", ls=\"-\", lw=1, edgecolor=\"gray\", ax=ax)\n",
    "    plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf135d",
   "metadata": {},
   "source": [
    "### Data distributions separated by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a958f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full dataset distribution separating by gender\n",
    "male_dataset = full_dataset[full_dataset[\"Gender\"] == \"Male\"]\n",
    "female_dataset = full_dataset[full_dataset[\"Gender\"] == \"Female\"]\n",
    "\n",
    "plt.figure(layout=\"compressed\", figsize=(12, 12))\n",
    "\n",
    "for i, column in enumerate(full_dataset):\n",
    "    ax = plt.subplot(plotsize, plotsize, i + 1)\n",
    "    sns.histplot(male_dataset[column], kde=True, color=\"yellow\", alpha=0.6, ls=\"-\", lw=1, edgecolor=\"gray\", ax=ax)\n",
    "    sns.histplot(female_dataset[column], kde=True, color=\"skyblue\", alpha=0.6, ls=\"-\", lw=1, edgecolor=\"gray\", ax=ax)\n",
    "    plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f87da",
   "metadata": {},
   "source": [
    "### Data distributions of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba62332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_categorical_distribution(df, column):\n",
    "    value_counts = df[column].value_counts()\n",
    "\n",
    "    plt.figure(layout=\"compressed\", figsize=(6, 6))\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.pie(value_counts, autopct='%0.001f%%', pctdistance=0.85, colors=[\"skyblue\", \"yellow\"])\n",
    "    centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
    "    ax.add_artist(centre_circle)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    sns.barplot(x=value_counts.index, y=value_counts.values, hue=value_counts.index, palette=[\"skyblue\", \"yellow\"], ax=ax)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1fdeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in CATEGORICAL_COLUMNS:\n",
    "    display_categorical_distribution(full_dataset, col)\n",
    "display_categorical_distribution(full_dataset, \"NObeyesdad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5230b55",
   "metadata": {},
   "source": [
    "### Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = full_dataset.select_dtypes(include='number').corr()\n",
    "\n",
    "plt.figure(layout=\"compressed\", figsize=(12, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\")\n",
    "plt.title('Correlation matrix')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe4cd13",
   "metadata": {},
   "source": [
    "## Split and save train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_dataset, test_dataset = train_test_split(full_dataset, test_size=0.1, random_state=SEED)\n",
    "\n",
    "TRAIN_DATASET_FILENAME.parent.mkdir(parents=True, exist_ok=True)\n",
    "TEST_DATASET_FILENAME.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_dataset.to_feather(TRAIN_DATASET_FILENAME)\n",
    "test_dataset.to_feather(TEST_DATASET_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5362e9",
   "metadata": {},
   "source": [
    "# Model training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66315596",
   "metadata": {},
   "source": [
    "## Load train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43909dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_feather(TRAIN_DATASET_FILENAME)\n",
    "test_dataset = pd.read_feather(TEST_DATASET_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d070fb8",
   "metadata": {},
   "source": [
    "## Data normalization and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10999397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(df):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    columns_to_scale = [col for col in df.columns if df[col].dtype == 'float']\n",
    "\n",
    "    scaled_df = df.copy()\n",
    "    for col in columns_to_scale:\n",
    "        scaled_df[col] = scaler.fit_transform(scaled_df[[col]])\n",
    "\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(df, categorical_columns):\n",
    "    encoded_df = df.copy()\n",
    "\n",
    "    dummy_cols = pd.get_dummies(encoded_df[categorical_columns], prefix=categorical_columns)\n",
    "    encoded_df = pd.concat([encoded_df, dummy_cols], axis=1)\n",
    "    encoded_df = encoded_df.drop(categorical_columns, axis=1)\n",
    "\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = encode_dataset(scale_dataset(train_dataset), CATEGORICAL_COLUMNS)\n",
    "test_dataset = encode_dataset(scale_dataset(test_dataset), CATEGORICAL_COLUMNS)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_dataset[\"NObeyesdad\"] = encoder.fit_transform(train_dataset[\"NObeyesdad\"])\n",
    "test_dataset[\"NObeyesdad\"] = encoder.transform(test_dataset[\"NObeyesdad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35fac5",
   "metadata": {},
   "source": [
    "## Create common columns after encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns present in test_dataset but not in train_dataset\n",
    "missing_in_train = set(test_dataset.columns) - set(train_dataset.columns)\n",
    "# Add missing columns to train_dataset\n",
    "for col in missing_in_train:\n",
    "    train_dataset[col] = False\n",
    "\n",
    "# Find columns present in train_dataset but not in test_dataset\n",
    "missing_in_test = set(train_dataset.columns) - set(test_dataset.columns)\n",
    "# Add missing columns to test_dataset\n",
    "for col in missing_in_test:\n",
    "    test_dataset[col] = False\n",
    "\n",
    "# Ensure the columns are in the same order\n",
    "train_dataset = train_dataset[test_dataset.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ab309",
   "metadata": {},
   "source": [
    "## Split features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c495b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop(\"NObeyesdad\", axis=1)\n",
    "y_train = train_dataset[\"NObeyesdad\"]\n",
    "\n",
    "X_test = test_dataset.drop(\"NObeyesdad\", axis=1)\n",
    "y_test = test_dataset[\"NObeyesdad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c9740a",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_find_best_model(list_of_models, X_train, y_train, X_test, y_test):\n",
    "    accuracies = [0.0] * len(list_of_models)\n",
    "\n",
    "    for i, model in enumerate(tqdm(list_of_models, ncols=PROGRESS_BAR_LENGTH)):\n",
    "        model.fit(X=X_train, y=y_train)\n",
    "        accuracies[i] = accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e5661",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": list(range(10, 101, 5)),\n",
    "    \"max_depth\": list(range(2, 16, 2)),\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "    \"learning_rate\": [0.05, 0.10, 0.15], \n",
    "}\n",
    "\n",
    "xgb_models = [\n",
    "    XGBClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_child_weight=params[\"min_child_weight\"],\n",
    "        booster=params[\"booster\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        random_state=SEED\n",
    "    )\n",
    "    for params in ParameterGrid(param_grid=param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = fit_and_find_best_model(xgb_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = xgb_models[np.argmax(accuracies)]\n",
    "\n",
    "# Validate on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred, target_names=list(encoder.classes_)))\n",
    "print(\"Confusion Matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=encoder.classes_).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9301f62",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc093c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": list(range(10, 101, 5)),\n",
    "    \"max_depth\": list(range(2, 16, 2)),\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"boosting_type\": [\"gbdt\", \"dart\"],\n",
    "    \"learning_rate\": [0.05, 0.10, 0.15], \n",
    "}\n",
    "\n",
    "lgbm_models = [\n",
    "    LGBMClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_child_weight=params[\"min_child_weight\"],\n",
    "        boosting_type=params[\"boosting_type\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        random_state=SEED\n",
    "    )\n",
    "    for params in ParameterGrid(param_grid=param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d4eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = fit_and_find_best_model(lgbm_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = lgbm_models[np.argmax(accuracies)]\n",
    "\n",
    "# Validate on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred, target_names=list(encoder.classes_)))\n",
    "print(\"Confusion Matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=encoder.classes_).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c921bb8",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31920cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"iterations\": [100, 250, 500, 1000],\n",
    "    \"depth\": list(range(1, 11)),\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 10, 100],\n",
    "    \"loss_function\": [\"MultiClass\", \"MultiClassOneVsAll\"],\n",
    "    \"border_count\": [5, 10, 32, 50, 100],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.3], \n",
    "}\n",
    "\n",
    "cb_models = [\n",
    "    CatBoostClassifier(\n",
    "        iterations=params[\"iterations\"],\n",
    "        depth=params[\"depth\"],\n",
    "        l2_leaf_reg=params[\"l2_leaf_reg\"],\n",
    "        loss_function=params[\"loss_function\"],\n",
    "        border_count=params[\"border_count\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        classes_count=len(encoder.classes_),\n",
    "        random_state=SEED\n",
    "    )\n",
    "    for params in ParameterGrid(param_grid=param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = fit_and_find_best_model(cb_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cb_models[np.argmax(accuracies)]\n",
    "\n",
    "# Validate on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred, target_names=list(encoder.classes_)))\n",
    "print(\"Confusion Matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=encoder.classes_).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a5c24a",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac359803",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": list(range(10, 101, 5)),\n",
    "    \"criterion\": [\"entropy\", \"gini\", \"log_loss\"],\n",
    "    \"max_depth\": list(range(2, 16, 2)),\n",
    "}\n",
    "\n",
    "rf_models = [\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        criterion=params[\"criterion\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        random_state=SEED\n",
    "    )\n",
    "    for params in ParameterGrid(param_grid=param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b7518",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = fit_and_find_best_model(rf_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rf_models[np.argmax(accuracies)]\n",
    "\n",
    "# Validate on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred, target_names=list(encoder.classes_)))\n",
    "print(\"Confusion Matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=encoder.classes_).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": list(np.linspace(0.1, 1, 10)),\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "}\n",
    "\n",
    "svc_models = [\n",
    "    SVC(\n",
    "        C=params[\"C\"],\n",
    "        kernel=params[\"kernel\"],\n",
    "        random_state=SEED\n",
    "    )\n",
    "    for params in ParameterGrid(param_grid=param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f58ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = fit_and_find_best_model(svc_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = svc_models[np.argmax(accuracies)]\n",
    "\n",
    "# Validate on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred, target_names=list(encoder.classes_)))\n",
    "print(\"Confusion Matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=encoder.classes_).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a6380",
   "metadata": {},
   "source": [
    "### k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31, 3)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"metric\": [\"cityblock\", \"euclidean\", \"l1\", \"l2\", \"manhattan\", \"minkowski\"],\n",
    "}\n",
    "\n",
    "knn_models = [\n",
    "    KNeighborsClassifier(\n",
    "        n_neighbors=params[\"n_neighbors\"],\n",
    "        weights=params[\"weights\"],\n",
    "        algorithm=params[\"algorithm\"],\n",
    "        metric=params[\"metric\"]\n",
    "    )\n",
    "    for params in ParameterGrid(param_grid=param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8de36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = fit_and_find_best_model(knn_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = knn_models[np.argmax(accuracies)]\n",
    "\n",
    "# Validate on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred, target_names=list(encoder.classes_)))\n",
    "print(\"Confusion Matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=encoder.classes_).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f204bf9",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": list(np.linspace(0.1, 1, 10)),\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"],\n",
    "}\n",
    "\n",
    "lr_models = [\n",
    "    LogisticRegression(\n",
    "        C=params[\"C\"],\n",
    "        solver=params[\"solver\"],\n",
    "        random_state=SEED\n",
    "    )\n",
    "    for params in ParameterGrid(param_grid=param_grid)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4258a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = fit_and_find_best_model(lr_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb32d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = lr_models[np.argmax(accuracies)]\n",
    "\n",
    "# Validate on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred, target_names=list(encoder.classes_)))\n",
    "print(\"Confusion Matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=encoder.classes_).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
